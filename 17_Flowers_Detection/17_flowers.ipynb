{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17 flowers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install wandb"
      ],
      "metadata": {
        "id": "99zthPTFO6Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dJVee_HDPLHB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "nHTmZ1Z6PYgc",
        "outputId": "5102f749-5bf9-4c44-9f37-a9e594f98096"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"17 Flowers\", entity=\"gharabadiyan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "_zm52R2RPdlE",
        "outputId": "d7fe8420-fa9f-4812-c606-b7efd2e34ab3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgharabadiyan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220721_053223-u4oipngh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/gharabadiyan/17%20Flowers/runs/u4oipngh\" target=\"_blank\">rich-puddle-1</a></strong> to <a href=\"https://wandb.ai/gharabadiyan/17%20Flowers\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/gharabadiyan/17%20Flowers/runs/u4oipngh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f97bce3c110>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "J3YNOdZLRdBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/Flowers/Train'\n",
        "width = height = 224\n",
        "batch_size = 32\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True,\n",
        "    brightness_range = (0.8,1.2),\n",
        "    zoom_range = 0.1,\n",
        "    shear_range = 0.3,\n",
        "    rotation_range = 10,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        "    subset = \"training\"\n",
        "\n",
        ")\n",
        "val_data = idg.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        "    subset = \"validation\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7C43c2lRUVU",
        "outputId": "c4bbb088-60e4-4394-f06b-4c0d5dc6fe16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 884 images belonging to 17 classes.\n",
            "Found 204 images belonging to 17 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "CIBHUGYjhvl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape=(width,height,3),\n",
        "    pooling = 'avg',\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        base_model,\n",
        "        Dropout(0.3), \n",
        "        # Flatten(),\n",
        "        # Dense(1024,activation='relu'),\n",
        "        # Dense(256,activation='relu'),\n",
        "        Dense(17,activation='softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYRizGOUXdG1",
        "outputId": "5a3d217a-28b7-45ca-c9d6-42faad786db3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:-2]:  #freeze layer\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "COWXKenOtbst"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WjijTVAcinGC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data,validation_data=val_data,epochs=10,callbacks=[WandbCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdJFK58cmTLB",
        "outputId": "5d8252ff-deef-4984-f0a2-55ca616c8b4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 528s 19s/step - loss: 2.4549 - accuracy: 0.2771 - val_loss: 1.4177 - val_accuracy: 0.6078 - _timestamp: 1658382140.0000 - _runtime: 597.0000\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 43s 2s/step - loss: 1.1884 - accuracy: 0.6538 - val_loss: 0.8182 - val_accuracy: 0.8137 - _timestamp: 1658382220.0000 - _runtime: 677.0000\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.7399 - accuracy: 0.8133 - val_loss: 0.6369 - val_accuracy: 0.8284 - _timestamp: 1658382302.0000 - _runtime: 759.0000\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.5687 - accuracy: 0.8518 - val_loss: 0.5065 - val_accuracy: 0.8676 - _timestamp: 1658382343.0000 - _runtime: 800.0000\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 42s 2s/step - loss: 0.4389 - accuracy: 0.8914 - val_loss: 0.4352 - val_accuracy: 0.8824 - _timestamp: 1658382386.0000 - _runtime: 843.0000\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.3868 - accuracy: 0.9095 - val_loss: 0.3766 - val_accuracy: 0.9020 - _timestamp: 1658382428.0000 - _runtime: 885.0000\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.3103 - accuracy: 0.9412 - val_loss: 0.3527 - val_accuracy: 0.8922 - _timestamp: 1658382470.0000 - _runtime: 927.0000\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 42s 2s/step - loss: 0.2643 - accuracy: 0.9480 - val_loss: 0.3261 - val_accuracy: 0.9167 - _timestamp: 1658382513.0000 - _runtime: 970.0000\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.2386 - accuracy: 0.9491 - val_loss: 0.3548 - val_accuracy: 0.8873 - _timestamp: 1658382555.0000 - _runtime: 1012.0000\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 42s 1s/step - loss: 0.2266 - accuracy: 0.9559 - val_loss: 0.3092 - val_accuracy: 0.9069 - _timestamp: 1658382597.0000 - _runtime: 1054.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97b801c850>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_path = '/content/drive/MyDrive/Flowers/Test'\n",
        "width=height = 224\n",
        "batch_size = 32\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        ")\n",
        "\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    test_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izbB5iunmlMU",
        "outputId": "1271fd98-37ca-405a-c81e-49adecbcb4b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 272 images belonging to 17 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmqcHkG-oL9j",
        "outputId": "25a97a35-7a67-4303-b4c1-3a1029c3a665"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 110s 14s/step - loss: 0.5871 - accuracy: 0.8162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5871051549911499, 0.8161764740943909]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/images (2).jpg')\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img,(width,height))\n",
        "img = img / 255.0\n",
        "\n",
        "img = img.reshape(1,width,height,3)\n",
        "\n",
        "start_time = time.time()\n",
        "result = model.predict(img)\n",
        "end_time = time.time()\n",
        "\n",
        "print(np.argmax(result))\n",
        "print(end_time - start_time)\n"
      ],
      "metadata": {
        "id": "0YCbgR5Vo8sf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a2813a-2832-4853-bcfd-bbaf590e3719"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "0.7624733448028564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "7xfLPwAwHhYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}