{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b9dFHtxGSw6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fe5aad-b9b3-4fe0-fd9d-b4419f265a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 76.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xiAOEJD7lQBJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "5l52NRwmS6sy",
        "outputId": "e0af2a57-edef-4062-95fe-e8da92b25429"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "G4Vh-NUVS9za",
        "outputId": "6d8afe40-5c43-4305-b8a1-f502cf9ab495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgharabadiyan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220721_085515-m123zeao</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/gharabadiyan/Face%20Mask%20Detection/runs/m123zeao\" target=\"_blank\">driven-shadow-1</a></strong> to <a href=\"https://wandb.ai/gharabadiyan/Face%20Mask%20Detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/gharabadiyan/Face%20Mask%20Detection/runs/m123zeao?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f17a67c1b90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.init(project=\"Face Mask Detection\", entity=\"gharabadiyan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR7-RUWpsIqa",
        "outputId": "63297001-f283-415a-befa-56fbf46405f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10012 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/Face Mask Dataset/Train'\n",
        "valid_dataset_path = '/content/drive/MyDrive/Face Mask Dataset/Validation'\n",
        "\n",
        "width = height = 224\n",
        "batch_size = 32\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True,\n",
        "    brightness_range = (0.6,1.2),\n",
        "    zoom_range = 0.1,\n",
        "    shear_range = 0.3,\n",
        "    rotation_range = 15,\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        "    subset = \"training\"\n",
        ")\n",
        "val_data = idg.flow_from_directory(\n",
        "    valid_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RsQss_EPilAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1082768-922a-44dd-d273-778bf53ecca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape=(width,height,3),\n",
        "    pooling = 'avg',\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        base_model,\n",
        "        Dropout(0.3), \n",
        "        Dense(2,activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "96Y-dhxakJ-J"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers[:-2]:  #freeze layer\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jM8pPdYvkPAI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy_EzdJukSV8",
        "outputId": "e40b44f1-ff44-4f9f-9d6a-aa3cdfbdf843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 2468s 8s/step - loss: 0.1124 - accuracy: 0.9572 - val_loss: 0.0315 - val_accuracy: 0.9937 - _timestamp: 1658396218.0000 - _runtime: 2503.0000\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 145s 464ms/step - loss: 0.0469 - accuracy: 0.9837 - val_loss: 0.0263 - val_accuracy: 0.9887 - _timestamp: 1658396363.0000 - _runtime: 2648.0000\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 145s 465ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 0.0241 - val_accuracy: 0.9937 - _timestamp: 1658396509.0000 - _runtime: 2794.0000\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 145s 464ms/step - loss: 0.0362 - accuracy: 0.9871 - val_loss: 0.0206 - val_accuracy: 0.9912 - _timestamp: 1658396654.0000 - _runtime: 2939.0000\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 145s 462ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.0169 - val_accuracy: 0.9950 - _timestamp: 1658396799.0000 - _runtime: 3084.0000\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 145s 463ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.0145 - val_accuracy: 0.9962 - _timestamp: 1658396944.0000 - _runtime: 3229.0000\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 145s 462ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.0129 - val_accuracy: 0.9950 - _timestamp: 1658397088.0000 - _runtime: 3373.0000\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 145s 464ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0115 - val_accuracy: 0.9962 - _timestamp: 1658397233.0000 - _runtime: 3518.0000\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 145s 465ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.0234 - val_accuracy: 0.9937 - _timestamp: 1658397379.0000 - _runtime: 3664.0000\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 146s 465ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0086 - val_accuracy: 0.9987 - _timestamp: 1658397524.0000 - _runtime: 3809.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1726583410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.fit(train_data,validation_data=val_data,epochs=10,callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "brqIoULRHetS"
      },
      "outputs": [],
      "source": [
        "model.save('Face_Mask.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-zRYiY_JkeZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b833de-af86-41f1-951d-84b4319afb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 992 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dataset_path = '/content/drive/MyDrive/Face Mask Dataset/Test'\n",
        "width=height = 224\n",
        "batch_size = 32\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        ")\n",
        "\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    test_dataset_path,\n",
        "    target_size = (width,height),\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EydGICFN9hyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ea5970-76bb-4d09-f58e-a2652f175be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 199s 7s/step - loss: 0.0223 - accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022283410653471947, 0.9939516186714172]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t32zXnZr9mWc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Face Mask Detection.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}